Простой усреднённый Word2Vec
В базовом варианте я просто брал все слова в документе, переходил к их Word2Vec-векторам и усреднял их. То есть вектор документа получался как обычное среднее по всем словам. Несмотря на то, что метод простой, он показал довольно хорошее качество классификации, около 0.81 по accuracy. Это можно объяснить тем, что в новостях тема текста хорошо отражается набором типичных слов, а Word2Vec уже умеет кодировать семантическую близость между словами. В итоге средний вектор получается чем-то вроде «центра» темы документа, и этого в данном корпусе оказалось достаточно, чтобы неплохо разделять новости по рубрикам.

TF‑IDF + Word2Vec
Дальше я попробовал улучшить базовый метод и применил TF‑IDF‑взвешивание. В этом варианте вектор документа тоже считается как среднее по векторам слов, но каждый вектор умножается на TF‑IDF веса соответствующего слова. Идея была в том, чтобы дать больший вес более «содержательным» словам и ослабить влияние слишком частых общих слов. Однако на практике качество получилось хуже — accuracy примерно 0.73. Одна из причин в том, что Word2Vec уже учитывает статистику совместных появлений слов и их контексты, поэтому дополнительное TF‑IDF‑взвешивание иногда, наоборот, слишком выделяет редкие слова и ослабляет более частотные, но важные для темы лексемы. Кроме того, для малочисленных классов (например, business, travel) специализированная лексика и так довольно редкая, и часть таких слов либо отбрасывается, либо почти не влияет из‑за маленьких весов, из‑за чего эти рубрики становятся хуже различимы.

Mean+Max pooling
Также был протестирован подход Mean+Max pooling. В этом случае для документа считаются два вектора: среднее по всем словесным векторам (mean) и покоординатный максимум (max), а затем они конкатенируются в один вектор. Теоретически это должно позволить одновременно учитывать общий «фон» текста (mean) и самые сильные лексические признаки (max). Но на этом наборе данных такой подход не дал стабильного выигрыша по сравнению с простым усреднением. Скорее всего, дело в том, что средний вектор уже достаточно хорошо описывает тематику новости, а max-часть дополнительно усиливает влияние отдельных «выбросов» и увеличивает размерность признакового пространства. Без тонкой настройки параметров классификатора это не приводит к росту качества.

Общий вывод
В итоге эксперименты показали, что для данного корпуса русскоязычных новостей лучше всего сработал самый простой вариант — обычное усреднение Word2Vec-векторов слов. Более сложные методы, такие как TF‑IDF + Word2Vec или Mean+Max pooling, требуют более аккуратной настройки (подбор параметров TF‑IDF, регуляризации у SVM и т.д.) и сами по себе не гарантируют улучшение качества по сравнению с базовым подходом.